param,value
env,mape
task,mape_simple_tag
n_agents,4
observation_sizes,[16, 16, 16, 14]
action_sizes,[5, 5, 5, 5]
discrete_actions,True
alg,maddpg
hidden_dim,128
curiosity,rnd
joint_curiosity,True
curiosity_hidden_dim,64
curiosity_state_rep_size,64
count_key_dim,32
count_decay,1
eta,5
curiosity_lr,2e-06
num_episodes,25000
max_episode_len,25
n_training_threads,6
no_rewards,False
sparse_rewards,False
sparse_freq,25
gamma,0.9
tau,0.01
lr,0.01
dropout_p,0.0
seed,2
steps_per_update,100
buffer_capacity,1000000
batch_size,1024
no_exploration,False
decay_factor,0.9999926317548481
exploration_bonus,1.0
n_exploration_eps,25000
init_noise_scale,0.3
final_noise_scale,0.0
display,False
save_frames,False
plot,False
eval_frequency,100
eval_episodes,5
dump_losses,False
run,mape_simple_tag_seed2_maddpg_rnd_joint_partialobservable_id25
save_models_dir,models
save_interval,1000
load_models,None
load_models_extension,final
scenario,simple_tag
partial_observable,True
observation_noise,False
environment_noise,False
