param,value
env,mape
task,mape_simple_adversary
n_agents,3
observation_sizes,[8, 10, 10]
action_sizes,[5, 5, 5]
discrete_actions,True
alg,maddpg
hidden_dim,128
curiosity,icm
joint_curiosity,False
curiosity_hidden_dim,128
curiosity_state_rep_size,64
count_key_dim,32
count_decay,1
eta,5
curiosity_lr,2e-06
num_episodes,25000
max_episode_len,25
n_training_threads,6
no_rewards,False
gamma,0.9
tau,0.01
lr,0.01
dropout_p,0.0
seed,1
steps_per_update,100
buffer_capacity,1000000
batch_size,1024
no_exploration,False
decay_factor,0.9999926317548481
exploration_bonus,1.0
n_exploration_eps,25000
init_noise_scale,0.3
final_noise_scale,0.0
display,False
save_frames,False
plot,False
eval_frequency,100
eval_episodes,5
dump_losses,False
run,mape_simple_adversary_seed1_maddpg_icm_eta5_id108
save_models_dir,models
save_interval,1000
load_models,None
load_models_extension,final
scenario,simple_adversary
partial_observable,False
